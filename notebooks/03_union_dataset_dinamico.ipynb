{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä 03 - Uni√≥n de Dataset (Din√°mico)\n",
    "\n",
    "**TFM: Predicci√≥n de Abandono Universitario**\n",
    "\n",
    "Este notebook:\n",
    "- Une todas las tablas en df_alumno\n",
    "- Genera reporte Sweetviz de df_alumno\n",
    "- Actualiza transformaciones_dinamico.html con df_alumno\n",
    "\n",
    "**Autora:** Mar√≠a Jos√© Morte (morte@uji.es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "INFORMACI√ìN DEL ENTORNO\n",
      "==================================================\n",
      "Entorno: local\n",
      "Ra√≠z proyecto: C:\\Users\\mjmor\\0.-TFM\\TFM_abandono_fase1_\n",
      "Data RAW: C:\\Users\\mjmor\\0.-TFM\\TFM_abandono_fase1_\\data\\01_raw\n",
      "Data INTERIM: C:\\Users\\mjmor\\0.-TFM\\TFM_abandono_fase1_\\data\\02_interim\n",
      "Data PROCESSED: C:\\Users\\mjmor\\0.-TFM\\TFM_abandono_fase1_\\data\\03_processed\n",
      "Docs: C:\\Users\\mjmor\\0.-TFM\\TFM_abandono_fase1_\\docs\n",
      "==================================================\n",
      "\n",
      "‚úÖ Configuraci√≥n cargada\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACI√ìN INICIAL\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar rutas\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "try:\n",
    "    from config import DATA_INTERIM, DATA_PROCESSED, DOCS, info_entorno\n",
    "    info_entorno()\n",
    "except ImportError:\n",
    "    DATA_INTERIM = Path('../data/02_interim')\n",
    "    DATA_PROCESSED = Path('../data/03_processed')\n",
    "    DOCS = Path('../docs')\n",
    "    print(f\"Usando rutas por defecto\")\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "DOCS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Configuraci√≥n cargada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar Tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CARGANDO TABLAS\n",
      "============================================================\n",
      "  Expedientes: 109,575 registros\n",
      "  Titulaciones: 45 registros\n",
      "  Nac_sexo: 30,873 registros\n",
      "  Domicilios: 109,206 registros\n",
      "  Becas: 70,524 registros\n",
      "  Trabajo: 195,524 registros\n",
      "  Notas: 107,908 registros\n",
      "  Recibos: 114,447 registros\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CARGAR TODAS LAS TABLAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CARGANDO TABLAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_exp = pd.read_parquet(DATA_INTERIM / 'expedientes_limpio.parquet')\n",
    "print(f\"  Expedientes: {len(df_exp):,} registros\")\n",
    "\n",
    "df_tit = pd.read_parquet(DATA_INTERIM / 'titulaciones_limpio.parquet')\n",
    "print(f\"  Titulaciones: {len(df_tit):,} registros\")\n",
    "\n",
    "df_nac = pd.read_parquet(DATA_INTERIM / 'nac_sexo_limpio.parquet')\n",
    "print(f\"  Nac_sexo: {len(df_nac):,} registros\")\n",
    "\n",
    "df_dom = pd.read_parquet(DATA_INTERIM / 'domicilios_limpio.parquet')\n",
    "print(f\"  Domicilios: {len(df_dom):,} registros\")\n",
    "\n",
    "df_becas = pd.read_parquet(DATA_INTERIM / 'becas_limpio.parquet')\n",
    "print(f\"  Becas: {len(df_becas):,} registros\")\n",
    "\n",
    "df_trabajo = pd.read_parquet(DATA_INTERIM / 'trabajo_limpio.parquet')\n",
    "print(f\"  Trabajo: {len(df_trabajo):,} registros\")\n",
    "\n",
    "df_notas = pd.read_parquet(DATA_INTERIM / 'notas_limpio.parquet')\n",
    "print(f\"  Notas: {len(df_notas):,} registros\")\n",
    "\n",
    "df_recibos = pd.read_parquet(DATA_INTERIM / 'recibos_limpio.parquet')\n",
    "print(f\"  Recibos: {len(df_recibos):,} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crear df_alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREANDO df_alumno\n",
      "============================================================\n",
      "\n",
      "1. Base: Expedientes...\n",
      "   Registros: 109,575\n",
      "\n",
      "2. A√±adiendo Titulaciones...\n",
      "   Registros: 109,575\n",
      "\n",
      "3. A√±adiendo Nac_sexo...\n",
      "   Registros: 109,575\n",
      "\n",
      "4. A√±adiendo Domicilios...\n",
      "   Registros: 109,575\n",
      "\n",
      "5. A√±adiendo Becas...\n",
      "   Registros: 109,575\n",
      "\n",
      "6. A√±adiendo Trabajo...\n",
      "   Registros: 109,575\n",
      "\n",
      "7. A√±adiendo Notas...\n",
      "   Registros: 109,575\n",
      "\n",
      "8. A√±adiendo Recibos...\n",
      "   Registros: 109,575\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREAR df_alumno - UNIR TODAS LAS TABLAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREANDO df_alumno\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Base: Expedientes\n",
    "print(\"\\n1. Base: Expedientes...\")\n",
    "df_alumno = df_exp.copy()\n",
    "print(f\"   Registros: {len(df_alumno):,}\")\n",
    "\n",
    "# + Titulaciones\n",
    "print(\"\\n2. A√±adiendo Titulaciones...\")\n",
    "df_alumno = df_alumno.merge(\n",
    "    df_tit[['exp_tit_id', 'titulacion_nombre', 'rama', 'cred_titulacion']],\n",
    "    on='exp_tit_id',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"   Registros: {len(df_alumno):,}\")\n",
    "\n",
    "# + Nac_sexo\n",
    "print(\"\\n3. A√±adiendo Nac_sexo...\")\n",
    "df_alumno = df_alumno.merge(\n",
    "    df_nac,\n",
    "    on='per_id_ficticio',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"   Registros: {len(df_alumno):,}\")\n",
    "\n",
    "# + Domicilios\n",
    "print(\"\\n4. A√±adiendo Domicilios...\")\n",
    "df_alumno = df_alumno.merge(\n",
    "    df_dom,\n",
    "    on=['per_id_ficticio', 'curso_aca'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"   Registros: {len(df_alumno):,}\")\n",
    "\n",
    "# + Becas (puede haber varias, cogemos la primera)\n",
    "print(\"\\n5. A√±adiendo Becas...\")\n",
    "df_becas_unico = df_becas.drop_duplicates(subset=['per_id_ficticio', 'curso_aca'], keep='first')\n",
    "df_alumno = df_alumno.merge(\n",
    "    df_becas_unico,\n",
    "    on=['per_id_ficticio', 'curso_aca'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"   Registros: {len(df_alumno):,}\")\n",
    "\n",
    "# + Trabajo\n",
    "print(\"\\n6. A√±adiendo Trabajo...\")\n",
    "df_trabajo_unico = df_trabajo.drop_duplicates(subset=['per_id_ficticio', 'curso_aca'], keep='first')\n",
    "df_alumno = df_alumno.merge(\n",
    "    df_trabajo_unico,\n",
    "    on=['per_id_ficticio', 'curso_aca'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"   Registros: {len(df_alumno):,}\")\n",
    "\n",
    "# + Notas\n",
    "print(\"\\n7. A√±adiendo Notas...\")\n",
    "df_notas_unico = df_notas.drop_duplicates(subset=['per_id_ficticio', 'curso_aca'], keep='first')\n",
    "df_alumno = df_alumno.merge(\n",
    "    df_notas_unico,\n",
    "    on=['per_id_ficticio', 'curso_aca'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"   Registros: {len(df_alumno):,}\")\n",
    "\n",
    "# + Recibos\n",
    "print(\"\\n8. A√±adiendo Recibos...\")\n",
    "df_recibos_unico = df_recibos.drop_duplicates(subset=['per_id_ficticio', 'curso_aca'], keep='first')\n",
    "df_alumno = df_alumno.merge(\n",
    "    df_recibos_unico,\n",
    "    on=['per_id_ficticio', 'curso_aca'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"   Registros: {len(df_alumno):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resumen df_alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESUMEN df_alumno\n",
      "============================================================\n",
      "Registros: 109,575\n",
      "Columnas: 30\n",
      "\n",
      "Columnas y % nulos:\n",
      "   per_id_ficticio: 0.0%\n",
      "   exp_tit_id: 0.0%\n",
      "   curso_aca: 0.0%\n",
      "   curso_aca_fin: 51.1%\n",
      "   nota_1: 52.5%\n",
      "   via_acceso: 0.0%\n",
      "   seguro: 0.0%\n",
      "   nota_selectividad_exp: 45.0%\n",
      "   nota_acceso_exp: 10.0%\n",
      "   cred_matriculados: 0.0%\n",
      "   cred_superados: 0.0%\n",
      "   egresado: 0.0%\n",
      "   nuevo: 0.0%\n",
      "   media_curso: 7.2%\n",
      "   titulacion_nombre: 0.0%\n",
      "   rama: 0.0%\n",
      "   cred_titulacion: 0.0%\n",
      "   sexo: 0.0%\n",
      "   pais: 0.0%\n",
      "   edad: 0.0%\n",
      "   poblacion: 0.0%\n",
      "   provincia: 0.0%\n",
      "   pais_domicilio: 0.0%\n",
      "   tipo_domicilio: 0.0%\n",
      "   beca: 46.9%\n",
      "   trabajo: 45.9%\n",
      "   media_titulacion_curso: 4.1%\n",
      "   media_alumno_curso: 4.1%\n",
      "   forma_pago: 0.0%\n",
      "   numero_pagos: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RESUMEN df_alumno\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN df_alumno\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Registros: {len(df_alumno):,}\")\n",
    "print(f\"Columnas: {len(df_alumno.columns)}\")\n",
    "print(f\"\\nColumnas y % nulos:\")\n",
    "for col in df_alumno.columns:\n",
    "    nulos = df_alumno[col].isna().sum()\n",
    "    pct = nulos / len(df_alumno) * 100\n",
    "    print(f\"   {col}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Guardar df_alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GUARDANDO df_alumno\n",
      "============================================================\n",
      "‚úÖ Guardado: df_alumno.parquet\n",
      "‚úÖ Guardado: df_alumno.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR df_alumno\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GUARDANDO df_alumno\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Parquet\n",
    "path_parquet = DATA_PROCESSED / 'df_alumno.parquet'\n",
    "df_alumno.to_parquet(path_parquet, index=False)\n",
    "print(f\"‚úÖ Guardado: {path_parquet.name}\")\n",
    "\n",
    "# CSV (para Power BI / Tableau)\n",
    "path_csv = DATA_PROCESSED / 'df_alumno.csv'\n",
    "df_alumno.to_csv(path_csv, index=False, encoding='utf-8-sig')\n",
    "print(f\"‚úÖ Guardado: {path_csv.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generar Reporte Sweetviz de df_alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERANDO REPORTE SWEETVIZ DE df_alumno\n",
      "============================================================\n",
      "Procesando... (puede tardar 1-2 minutos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a5df0969e845049c6890ba48717d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report C:\\Users\\mjmor\\0.-TFM\\TFM_abandono_fase1_\\docs\\reporte_df_alumno.html was generated.\n",
      "‚úÖ Guardado: reporte_df_alumno.html\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GENERAR REPORTE SWEETVIZ DE df_alumno\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERANDO REPORTE SWEETVIZ DE df_alumno\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Parchear numpy\n",
    "import numpy as np\n",
    "if not hasattr(np, 'VisibleDeprecationWarning'):\n",
    "    np.VisibleDeprecationWarning = np.exceptions.VisibleDeprecationWarning\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "print(\"Procesando... (puede tardar 1-2 minutos)\")\n",
    "reporte = sv.analyze(df_alumno, pairwise_analysis='off')\n",
    "\n",
    "# Guardar\n",
    "html_path = DOCS / 'reporte_df_alumno.html'\n",
    "reporte.show_html(str(html_path), open_browser=False)\n",
    "\n",
    "print(f\"‚úÖ Guardado: {html_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Actualizar transformaciones_dinamico.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ACTUALIZANDO transformaciones_dinamico.html\n",
      "============================================================\n",
      "‚úÖ Actualizado: transformaciones_dinamico.html\n",
      "   df_alumno: 109,575 registros, 30 columnas\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ACTUALIZAR transformaciones_dinamico.html CON df_alumno\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ACTUALIZANDO transformaciones_dinamico.html\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trans_path = DOCS / 'transformaciones_dinamico.html'\n",
    "\n",
    "# Leer HTML existente\n",
    "with open(trans_path, 'r', encoding='utf-8') as f:\n",
    "    html = f.read()\n",
    "\n",
    "# Reemplazar el div placeholder de df_alumno por el enlace real\n",
    "old_div = '''<div id=\"df-alumno-container\" class=\"bg-gray-300 rounded-xl p-6 text-gray-600 text-center\">\n",
    "                    <div class=\"text-2xl font-bold\">üéØ df_alumno.parquet</div>\n",
    "                    <div class=\"text-lg opacity-90\">Pendiente de generar</div>\n",
    "                    <div class=\"text-sm opacity-75 mt-2\">Ejecuta 03_union_dataset_dinamico.ipynb</div>\n",
    "                </div>'''\n",
    "\n",
    "new_div = f'''<a href=\"reporte_df_alumno.html\" target=\"_blank\" class=\"df-alumno-link transition-all\">\n",
    "                    <div class=\"bg-gradient-to-r from-green-400 to-blue-500 rounded-xl p-6 text-white text-center shadow-lg hover:shadow-2xl cursor-pointer\">\n",
    "                        <div class=\"text-2xl font-bold\">üéØ df_alumno.parquet</div>\n",
    "                        <div class=\"text-lg opacity-90\">Dataset unificado para modelado</div>\n",
    "                        <div class=\"text-sm opacity-75 mt-2\">{len(df_alumno):,} registros | {len(df_alumno.columns)} columnas</div>\n",
    "                        <div class=\"text-xs mt-3 bg-white/20 rounded px-3 py-1 inline-block\">üìä Clic para ver Reporte Sweetviz</div>\n",
    "                    </div>\n",
    "                </a>'''\n",
    "\n",
    "html = html.replace(old_div, new_div)\n",
    "\n",
    "# Guardar\n",
    "with open(trans_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(html)\n",
    "\n",
    "print(f\"‚úÖ Actualizado: {trans_path.name}\")\n",
    "print(f\"   df_alumno: {len(df_alumno):,} registros, {len(df_alumno.columns)} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESUMEN FINAL - FASE 1 COMPLETADA\n",
      "============================================================\n",
      "\n",
      "üìÅ FICHEROS GENERADOS:\n",
      "\n",
      "data/03_processed/:\n",
      "  df_alumno.csv (26728.4 KB)\n",
      "  df_alumno.parquet (1927.1 KB)\n",
      "\n",
      "docs/:\n",
      "  reporte_becas.html (591.1 KB)\n",
      "  reporte_df_alumno.html (1856.6 KB)\n",
      "  reporte_domicilios.html (683.0 KB)\n",
      "  reporte_expedientes.html (1185.9 KB)\n",
      "  reporte_nac_sexo.html (592.1 KB)\n",
      "  reporte_notas.html (676.4 KB)\n",
      "  reporte_preinscripcion.html (906.1 KB)\n",
      "  reporte_recibos.html (568.7 KB)\n",
      "  reporte_titulaciones.html (580.0 KB)\n",
      "  reporte_trabajo.html (585.9 KB)\n",
      "  transformaciones_dinamico.html (29.9 KB)\n",
      "\n",
      "============================================================\n",
      "‚úÖ FASE 1 COMPLETADA\n",
      "============================================================\n",
      "\n",
      "Para ver los resultados:\n",
      "  Abre docs/transformaciones_dinamico.html en tu navegador\n",
      "\n",
      "Siguiente paso: FASE 2 - EDA (An√°lisis Exploratorio)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RESUMEN FINAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN FINAL - FASE 1 COMPLETADA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìÅ FICHEROS GENERADOS:\")\n",
    "\n",
    "print(\"\\ndata/03_processed/:\")\n",
    "for f in sorted(DATA_PROCESSED.glob('*')):\n",
    "    if f.is_file() and not f.name.startswith('.'):\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f\"  {f.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(\"\\ndocs/:\")\n",
    "for f in sorted(DOCS.glob('*.html')):\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f\"  {f.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ FASE 1 COMPLETADA\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPara ver los resultados:\")\n",
    "print(\"  Abre docs/transformaciones_dinamico.html en tu navegador\")\n",
    "print(\"\\nSiguiente paso: FASE 2 - EDA (An√°lisis Exploratorio)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_tfm)",
   "language": "python",
   "name": "env_tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
